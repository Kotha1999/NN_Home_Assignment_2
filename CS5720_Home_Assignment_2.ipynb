{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# CS5720 - Home Assignment 2\n", "**University of Central Missouri**  \n", "**Neural Networks and Deep Learning - Summer 2025**  \n", "**Student Name: ____________________ | Student ID: ____________**\n", "\n", "This notebook covers:\n", "- Convolution Operations with Different Parameters\n", "- CNN Feature Extraction with Filters and Pooling\n", "- Data Preprocessing: Normalization vs Standardization"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Required Libraries\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import tensorflow as tf\n", "from tensorflow.keras.layers import Conv2D\n", "import cv2\n", "from sklearn.datasets import load_iris\n", "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.model_selection import train_test_split\n", "import seaborn as sns"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Q1: Convolution with Different Parameters"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Define 5x5 Input and 3x3 Kernel\n", "input_matrix = np.array([[1, 2, 3, 0, 1],\n", "                         [0, 1, 2, 3, 1],\n", "                         [1, 0, 1, 2, 2],\n", "                         [2, 1, 0, 1, 1],\n", "                         [0, 1, 2, 1, 0]], dtype=np.float32)\n", "kernel = np.array([[1, 0, -1],\n", "                   [1, 0, -1],\n", "                   [1, 0, -1]], dtype=np.float32)\n", "\n", "input_tensor = tf.constant(input_matrix.reshape(1, 5, 5, 1))\n", "kernel_tensor = tf.constant(kernel.reshape(3, 3, 1, 1))\n", "\n", "for stride in [1, 2]:\n", "    for padding in ['VALID', 'SAME']:\n", "        conv_result = tf.nn.conv2d(input_tensor, kernel_tensor, strides=[1, stride, stride, 1], padding=padding)\n", "        print(f\"Stride={stride}, Padding={padding}\\n\", tf.squeeze(conv_result).numpy())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Q2: CNN Feature Extraction - Edge Detection"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Upload Image Manually in Colab if needed\n", "from google.colab import files\n", "uploaded = files.upload()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Apply Sobel Filters\n", "image = cv2.imread(list(uploaded.keys())[0], cv2.IMREAD_GRAYSCALE)\n", "sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n", "sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n", "\n", "plt.figure(figsize=(12,4))\n", "plt.subplot(1,3,1); plt.imshow(image, cmap='gray'); plt.title(\"Original\")\n", "plt.subplot(1,3,2); plt.imshow(sobel_x, cmap='gray'); plt.title(\"Sobel-X\")\n", "plt.subplot(1,3,3); plt.imshow(sobel_y, cmap='gray'); plt.title(\"Sobel-Y\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Q2: CNN Feature Extraction - Pooling"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Max and Average Pooling\n", "input_matrix = np.random.rand(1, 4, 4, 1).astype(np.float32)\n", "max_pool = tf.nn.max_pool2d(input_matrix, ksize=2, strides=2, padding='VALID')\n", "avg_pool = tf.nn.avg_pool2d(input_matrix, ksize=2, strides=2, padding='VALID')\n", "print(\"Original:\\n\", tf.squeeze(input_matrix).numpy())\n", "print(\"Max Pooled:\\n\", tf.squeeze(max_pool).numpy())\n", "print(\"Avg Pooled:\\n\", tf.squeeze(avg_pool).numpy())"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Q3: Data Preprocessing \u2013 Normalization vs. Standardization"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load and Transform Iris Dataset\n", "iris = load_iris()\n", "X = iris.data\n", "y = iris.target\n", "\n", "# Min-Max Normalization\n", "minmax = MinMaxScaler().fit_transform(X)\n", "# Z-score Standardization\n", "zscore = StandardScaler().fit_transform(X)\n", "\n", "# Visualize\n", "plt.figure(figsize=(10,4))\n", "sns.histplot(minmax[:, 0], kde=True, label='Min-Max')\n", "sns.histplot(zscore[:, 0], kde=True, label='Z-Score')\n", "plt.legend(); plt.title(\"Feature Distribution After Scaling\")\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Train Logistic Regression and Compare Accuracy\n", "for name, X_trans in zip(['Raw', 'MinMax', 'ZScore'], [X, minmax, zscore]):\n", "    X_train, X_test, y_train, y_test = train_test_split(X_trans, y, test_size=0.3, random_state=42)\n", "    model = LogisticRegression(max_iter=200)\n", "    model.fit(X_train, y_train)\n", "    acc = model.score(X_test, y_test)\n", "    print(f\"{name} Accuracy: {acc:.4f}\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.9"}}, "nbformat": 4, "nbformat_minor": 5}